{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSPC dataset - eco-velo\n",
    "\n",
    "**In this Notebook we will be applying eco-velo on the HSPC dataset This dataset has been presented for the first time by Yasmin Demerdash on the EHA (European Hematology Association) 2022 Congress. The corresponding paper will be published on Biorxiv at end September (keep an eye out for Bouman and Demerdash et al.).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load libraries\n",
    "\n",
    "# general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# single-cell libraries\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dimension reduction libraries\n",
    "from sklearn.decomposition import PCA #for creating PCAs\n",
    "from sklearn.preprocessing import StandardScaler #for creating PCAs\n",
    "import umap\n",
    "from scipy.spatial import cKDTree #used for smooting\n",
    "\n",
    "# other\n",
    "import sklearn as sk #used for L2 normalization\n",
    "\n",
    "# import our own functions\n",
    "import velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "Here, we load the spliced and unspliced matrices from the original dataset, as well as the original clusters, colours and t-SNE embedding. All of the files used here can be downloaded from this webpage: http://pklab.med.harvard.edu/velocyto/notebooks/R/chromaffin2.nb.html (a tutorial on velocyto provided by La Manno and the Karchenko lab). The original file name is `onefilepercell_A1_unique_and_others_J2CH1.loom `, which we renamed to `chromaffin.loom`. The files with the cell colors/clusters (`cell_colors.csv`) and the t-SNE embedding (`embedding.csv`) can be found on this GitHub page under datasets/chromaffin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "### load loom file subset\n",
    "hspc_path = \"../datasets/HSPC/HSPC.loom\"\n",
    "adata = ad.read_loom(hspc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load cells selected in qc\n",
    "load_path = \"../datasets/HSPC/cells_after_qc.csv\"\n",
    "cell_after_qc = np.loadtxt(load_path, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change cellnames in loom file to match the cellnames from the original dataset\n",
    "cellnames = [cellname.replace('possorted_genome_bam_YBF44:','') for cellname in adata.obs_names]\n",
    "cellnames = [cellname.replace('x','-1-PBS') for cellname in cellnames]\n",
    "adata.obs_names = cellnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove cells that are filtered out in original pipeline (doublets, etc.)\n",
    "adata = adata[cell_after_qc,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "### make names of genes unique\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load genes selected in qc\n",
    "load_path = \"../datasets/HSPC/genes_after_qc.csv\"\n",
    "genes_after_qc = np.loadtxt(load_path, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove genes that are filtered out in original pipeline \n",
    "shared_genes = np.intersect1d(adata.var_names, genes_after_qc)\n",
    "adata = adata[:,shared_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    }
   ],
   "source": [
    "### load original clusters \n",
    "load_path = \"../datasets/HSPC/original_clusters.csv\"\n",
    "original_clusters = pd.read_csv(load_path, index_col=0)\n",
    "adata.obs[\"original_clusters\"] = original_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load original colors\n",
    "original_colors = ['#98df8a', '#d62728', '#aec7e8', '#17becf', '#8c564b', '#b5bd61',\n",
    "                   '#e377c2', '#279e68', '#ff7f0e', '#aa40fc', '#1f77b4', '#ffbb78']\n",
    "adata.uns[\"original_clusters_colors\"] = original_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load original UMAP\n",
    "load_path = \"../datasets/HSPC/original_UMAP.csv\"\n",
    "original_umap = np.genfromtxt(load_path, delimiter=',')\n",
    "adata.obsm[\"original_umap\"] = original_umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove smaller populations\n",
    "small_populations = [\"Eosinophils\", \"Monocytes\"]\n",
    "adata = adata[[i not in small_populations for i in adata.obs[\"original_clusters\"]],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2430"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load cell type colors \n",
    "load_path = \"../datasets/HSPC/celltypes_colors.csv\"\n",
    "celltypes_colors = pd.read_csv(load_path, header=None).iloc[:,0].values\n",
    "len(celltypes_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_copy = adata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing\n",
    "Here, we will process the dataset according to the eco-velo processing workflow. We will select the highly variable genes (HVGs), filter for genes with sufficient unspliced an spliced counts, log-transform the data and last we L2 normalise the spliced and unspliced separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert matrices from sparse to dense\n",
    "adata.X = adata.X.todense()\n",
    "adata.layers['spliced'] = adata.layers['spliced'].todense()\n",
    "adata.layers['unspliced'] = adata.layers['unspliced'].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vmarotl/Documents/rna_velocity/velocity_package/velocity/processing/filtering.py:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  z = (counts - mu) / np.sqrt(mu + (np.square(mu) / theta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting to top 2000 highly-variable genes.\n"
     ]
    }
   ],
   "source": [
    "### select HVGs\n",
    "hvgs = velocity.pp.filtering.get_hvgs(adata, no_of_hvgs=2000, theta=100, layer='spliced')\n",
    "print(\"Subsetting to top \" + str(len(hvgs)) + \" highly-variable genes.\")\n",
    "adata = adata[:, hvgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting to 266 genes with sufficient S and U counts.\n"
     ]
    }
   ],
   "source": [
    "### subset for genes that have high enough U and S counts\n",
    "minlim = 6\n",
    "us_genes = velocity.pp.filtering.get_high_us_genes(adata, minlim_u=minlim, minlim_s=minlim)\n",
    "print(\"Subsetting to \" + str(len(us_genes)) + \" genes with sufficient S and U counts.\")\n",
    "adata = adata[:,us_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-2cdb89a132c5>:3: RuntimeWarning: divide by zero encountered in log\n",
      "  adata.layers['spliced'] = np.matrix(np.where(adata.layers['spliced'] != 0, np.log(adata.layers['spliced']), 0))\n",
      "<ipython-input-18-2cdb89a132c5>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  adata.layers['unspliced'] = np.matrix(np.where(adata.layers['unspliced'] != 0, np.log(adata.layers['unspliced']), 0))\n"
     ]
    }
   ],
   "source": [
    "### log transformation of the dataset\n",
    "#adata.X = np.matrix(np.where(adata.X != 0, np.log(adata.X), 0))\n",
    "adata.layers['spliced'] = np.matrix(np.where(adata.layers['spliced'] != 0, np.log(adata.layers['spliced']), 0))\n",
    "adata.layers['unspliced'] = np.matrix(np.where(adata.layers['unspliced'] != 0, np.log(adata.layers['unspliced']), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = adata.layers['spliced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### L2 normalise spliced and unspliced separately\n",
    "adata.X = sk.preprocessing.normalize(adata.X, norm='l2')\n",
    "adata.layers['spliced'] = sk.preprocessing.normalize(adata.layers['spliced'], norm='l2')\n",
    "adata.layers['unspliced'] = sk.preprocessing.normalize(adata.layers['unspliced'], norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find MNN on gene space\n",
    "In the eco-velo workflow, for each cell we use its unspliced counts and try to find the top N mutual nearest neighbours (MNNs), defined by their spliced counts. We later use the MNNs to plot the velocities onto the embeddings.\n",
    "\n",
    "Note: since we try to find an MNN in the first 50 neighbours, it might be that some cells are not assigned to any MNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 2430 × 266\n",
       "    obs: 'original_clusters'\n",
       "    var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'\n",
       "    uns: 'original_clusters_colors'\n",
       "    obsm: 'original_umap'\n",
       "    layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells without assigned MNN: 1594 out of 2430 cells.\n"
     ]
    }
   ],
   "source": [
    "### identify MNNs\n",
    "k = 50\n",
    "mnn = velocity.tl.eco_velo.find_mutual_nn(adata.layers['unspliced'], adata.layers['spliced'], top_n=5, k = k)\n",
    "print(\"Cells without assigned MNN: \" + str(np.sum(np.all(mnn==-1, axis=1))) + \" out of \" + str(len(adata)) + \" cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "Last, we are going to use the MNNs to create the velocity plots. \n",
    "\n",
    "**Calculate UMAP embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### scale data (spliced counts)\n",
    "scal = StandardScaler()\n",
    "spliced_scaled = scal.fit_transform(adata.layers[\"spliced\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run PCA\n",
    "n_pcs = 15\n",
    "pca = PCA(n_components=n_pcs, random_state=0)\n",
    "pca.fit(spliced_scaled)\n",
    "pca_pts = pca.transform(spliced_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate UMAP\n",
    "reducer = umap.UMAP(random_state=0, n_neighbors=30, min_dist=1, n_components=2, metric=\"euclidean\")\n",
    "UMAP_data = reducer.fit_transform(pca_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot UMAP embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get colors of each cluster\n",
    "cell_colors=celltypes_colors\n",
    "light_color = np.array([velocity.pl.utils.lighten_color(i, .3) for i in cell_colors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot UMAP (just spliced counts)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3), frameon=False)\n",
    "ax.scatter(UMAP_data[:,0], UMAP_data[:,1], s=10, c=cell_colors)\n",
    "fig.tight_layout()\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get future states for each cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### select MNNs\n",
    "pos = UMAP_data[mnn]\n",
    "pos[np.array(mnn)==-1]=np.nan\n",
    "pos = np.nanmean(pos, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### smoothing; averaging position over nearest neighbours\n",
    "NN = cKDTree(adata.layers['spliced']).query(x=adata.layers['spliced'], k=30)[1]\n",
    "pos_mean = np.nanmean(np.array(pos)[NN], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot future states in UMAP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get points for UMAP\n",
    "v = np.array(pos) - UMAP_data\n",
    "v_mean = pos_mean - UMAP_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"scale\": 5, \"angles\": \"xy\", \"scale_units\": \"xy\", \"edgecolors\": \"k\", \n",
    "          \"linewidth\": 0.5, \"headwidth\": 5, \"headaxislength\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot arrows not for all cells (for less crowded)\n",
    "sub=np.ones(adata.shape[0])  \n",
    "sub[np.arange(0, adata.shape[0], 2)]=0\n",
    "sub = sub.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create PCA plot of pancreas by kappa-velo\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# plot points (cells) and arrows (velocities)\n",
    "axs[0].scatter(UMAP_data[:,0], UMAP_data[:,1], color=light_color, s=200)\n",
    "axs[1].scatter(UMAP_data[:,0], UMAP_data[:,1], color=light_color, s=200)\n",
    "\n",
    "# make pretty\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_yticks([])\n",
    "axs[0].set_facecolor('white')\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_facecolor('white')\n",
    "fig.patch.set_alpha(0)\n",
    "\n",
    "# axis labels\n",
    "axs[0].set_xlabel(\"UMAP1\", fontsize=18)\n",
    "axs[0].set_ylabel(\"UMAP2\", fontsize=18)\n",
    "axs[1].set_xlabel(\"UMAP1\", fontsize=18)\n",
    "axs[1].set_ylabel(\"UMAP2\", fontsize=18)\n",
    "\n",
    "# title\n",
    "axs[0].set_title(\"eco-velo velocities on UMAP\", fontsize=20, fontweight=\"bold\")\n",
    "axs[1].set_title(\"eco-velo velocities on UMAP (smoothed)\", fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "\n",
    "# plot arrows \n",
    "axs[0].quiver(UMAP_data[:,0], UMAP_data[:,1], v[:,0], v[:,1], color=cell_colors, **kwargs)\n",
    "axs[1].quiver(UMAP_data[sub,0], UMAP_data[sub,1], v_mean[sub,0], v_mean[sub,1], color=cell_colors[sub], **kwargs)\n",
    "\n",
    "# save plot\n",
    "plt.tight_layout()\n",
    "save_path = \"../figures/HSPC/HSPC_eco-velo_UMAP.pdf\"\n",
    "plt.savefig(save_path, dpi=300, transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clone",
   "language": "python",
   "name": "clone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
